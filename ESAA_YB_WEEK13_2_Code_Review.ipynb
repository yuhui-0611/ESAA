{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuhui-0611/ESAA/blob/main/ESAA_YB_WEEK13_2_Code_Review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **스마트 해운물류 x AI 미션 챌린지 : 이상신호 감지 기반 비정상 작동 진단**"
      ],
      "metadata": {
        "id": "EcmYXpCb8RaO"
      },
      "id": "EcmYXpCb8RaO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://dacon.io/competitions/official/236590/codeshare/13593?page=1&dtype=recent)"
      ],
      "metadata": {
        "id": "0cDpFO-d8UPu"
      },
      "id": "0cDpFO-d8UPu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ID : 샘플별 고유 ID\n",
        "- X_01 ~ X_52\n",
        "> 스케일·분포는 피처별로 상이할 수 있음\n",
        "- target : 고장 진단 target"
      ],
      "metadata": {
        "id": "wRrvRLS9BE4a"
      },
      "id": "wRrvRLS9BE4a"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f120ec25",
      "metadata": {
        "id": "f120ec25"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iZvWY1L_xRG",
        "outputId": "835f17ce-53f2-4c91-b697-1652140af0df"
      },
      "id": "2iZvWY1L_xRG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5ad1f198",
      "metadata": {
        "id": "5ad1f198"
      },
      "outputs": [],
      "source": [
        "# 환경 설정 및 데이터 로딩\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON/train_smart.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON/test_smart.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 피처와 타깃 분리"
      ],
      "metadata": {
        "id": "6xYZaZ_kBjhi"
      },
      "id": "6xYZaZ_kBjhi"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf9a1cf4",
      "metadata": {
        "id": "bf9a1cf4"
      },
      "outputs": [],
      "source": [
        "# 피처 선택 및 전처리\n",
        "feature_cols = [col for col in train.columns if col.startswith('X_')]\n",
        "train_x = train[feature_cols]\n",
        "train_y = train['target']\n",
        "test_x = test[feature_cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 다중공선성 제거"
      ],
      "metadata": {
        "id": "dbibThotByHP"
      },
      "id": "dbibThotByHP"
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_multicollinearity(df, threshold=0.95):\n",
        "    # 피처 간 상관계수 행렬\n",
        "    corr_matrix = df.corr().abs()\n",
        "\n",
        "    # 상삼각형만 남김\n",
        "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "    # 상관계수 > 0.95면 → 제거 대상\n",
        "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
        "\n",
        "    # 제거된 피처 이름 리스트 반환\n",
        "    return df.drop(columns=to_drop), to_drop\n",
        "# function end\n",
        "\n",
        "# train 기준으로 제거 피처 결정 → test에 그대로 적용\n",
        "train_x_clean, dropped_features = remove_multicollinearity(train_x, threshold=0.95)\n",
        "test_x_clean = test_x.drop(columns=dropped_features)"
      ],
      "metadata": {
        "id": "_2VLSz0WBtqZ"
      },
      "id": "_2VLSz0WBtqZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. fit_transform\n",
        "\n",
        "- 전체 피처 중 정보량이 많은 상위 20개만 선택\n",
        "\n",
        "Mutual Information이란?\n",
        "- X를 알면 Y에 대한 불확실성이 얼마나 줄어드나?\n",
        "- 비선형 관계도 잡아냄\n",
        "- 신경망과 궁합이 매우 좋음"
      ],
      "metadata": {
        "id": "PEUqBqTzCv7r"
      },
      "id": "PEUqBqTzCv7r"
    },
    {
      "cell_type": "code",
      "source": [
        "K_BEST = 20\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=K_BEST)\n",
        "\n",
        "# train에서만 fit, test는 transform만\n",
        "train_x_selected = selector.fit_transform(train_x_clean, train_y)\n",
        "test_x_selected = selector.transform(test_x_clean)\n",
        "\n",
        "# 선택된 피처 이름 추출\n",
        "selected_features = train_x_clean.columns[selector.get_support()].tolist()\n",
        "\n",
        "train_x_selected_df = pd.DataFrame(train_x_selected, columns=selected_features)\n",
        "test_x_selected_df = pd.DataFrame(test_x_selected, columns=selected_features)\n",
        "\n",
        "# 이상치 대응\n",
        "scaler = RobustScaler()\n",
        "train_x_scaled = scaler.fit_transform(train_x_selected_df)\n",
        "test_x_scaled = scaler.transform(test_x_selected_df)"
      ],
      "metadata": {
        "id": "hNVTmJt6CqwV"
      },
      "id": "hNVTmJt6CqwV",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_support() ?\n",
        "- 피처 선택 결과로, \"선택된 피처가 True, 버려진 피처가 False\"인 마스크(mask)를 반환하는 함수\n",
        "- fit이 끝난 뒤에만 쓸 수 있음\n",
        "- 반환값: boolean 배열\n",
        "> array([ True, False, True, False, False, True])\n",
        "\n",
        "\n",
        "```\n",
        "selected_features = train_x_clean.columns[selector.get_support()]\n",
        "```\n",
        "이 줄의 의미를 풀면:\n",
        "- train_x_clean.columns → 전체 피처 이름 배열\n",
        "- selector.get_support() → True/False 마스크\n",
        "\n",
        "> True 위치의 컬럼 이름만 골라냄\n"
      ],
      "metadata": {
        "id": "rcAdnSFtD7MH"
      },
      "id": "rcAdnSFtD7MH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a9ecca9",
      "metadata": {
        "id": "7a9ecca9"
      },
      "outputs": [],
      "source": [
        "# MLP 모델 정의\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.3):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            prev_dim = hidden_dim\n",
        "        layers.append(nn.Linear(prev_dim, output_dim))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de4d0b4",
      "metadata": {
        "id": "2de4d0b4"
      },
      "outputs": [],
      "source": [
        "# K-Fold 학습 및 앙상블\n",
        "INPUT_DIM = train_x_scaled.shape[1]\n",
        "HIDDEN_DIMS = [256, 128, 64, 32]\n",
        "OUTPUT_DIM = train_y.nunique()\n",
        "DROPOUT_RATE = 0.3\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 100\n",
        "PATIENCE = 15\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "N_SPLITS = 5\n",
        "kfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "fold_results = []\n",
        "fold_models = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_x_scaled, train_y), 1):\n",
        "    X_fold_train = train_x_scaled[train_idx]\n",
        "    y_fold_train = train_y.iloc[train_idx]\n",
        "    X_fold_val = train_x_scaled[val_idx]\n",
        "    y_fold_val = train_y.iloc[val_idx]\n",
        "\n",
        "    X_train_tensor = torch.FloatTensor(X_fold_train)\n",
        "    y_train_tensor = torch.LongTensor(y_fold_train.values)\n",
        "    X_val_tensor = torch.FloatTensor(X_fold_val)\n",
        "    y_val_tensor = torch.LongTensor(y_fold_val.values)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = MLPClassifier(INPUT_DIM, HIDDEN_DIMS, OUTPUT_DIM, DROPOUT_RATE).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    best_val_f1 = 0.0\n",
        "    best_model_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        train_preds = []\n",
        "        train_labels = []\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_preds.extend(predicted.cpu().numpy())\n",
        "            train_labels.extend(batch_y.cpu().numpy())\n",
        "        train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in val_loader:\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "                outputs = model(batch_X)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_preds.extend(predicted.cpu().numpy())\n",
        "                val_labels.extend(batch_y.cpu().numpy())\n",
        "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            break\n",
        "\n",
        "    fold_results.append(best_val_f1)\n",
        "    fold_models.append(best_model_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecfbe8c9",
      "metadata": {
        "id": "ecfbe8c9"
      },
      "outputs": [],
      "source": [
        "# 테스트 데이터 예측 및 제출 파일 생성\n",
        "test_x_tensor = torch.FloatTensor(test_x_scaled).to(device)\n",
        "all_fold_predictions = []\n",
        "for model_state in fold_models:\n",
        "    model = MLPClassifier(INPUT_DIM, HIDDEN_DIMS, OUTPUT_DIM, DROPOUT_RATE).to(device)\n",
        "    model.load_state_dict(model_state)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(test_x_tensor)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        all_fold_predictions.append(probabilities.cpu().numpy())\n",
        "ensemble_probabilities = np.mean(all_fold_predictions, axis=0)\n",
        "ensemble_predictions = np.argmax(ensemble_probabilities, axis=1)\n",
        "\n",
        "submission = pd.read_csv('./data/sample_submission.csv')\n",
        "submission['target'] = ensemble_predictions\n",
        "submission.to_csv('./submission/mlp_kfold_ensemble.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}